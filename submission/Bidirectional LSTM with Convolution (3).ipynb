{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"def fetch(folder):\n    flag=False\n    read = lambda imname: np.asarray((Image.open(imname).convert(\"L\")).resize((320, 240), Image.ANTIALIAS))\n    ims = [read(os.path.join(folder, filename)) for filename in os.listdir(folder)]\n    im_array = np.array(ims, dtype='uint8')    \n\n    ch1_arr = np.empty((1))\n    ch2_arr = np.empty((1))\n    ch3_arr = np.empty((1))\n    ch4_arr = np.empty((1))\n    ch5_arr = np.empty((1))\n    ch6_arr = np.empty((1))\n\n    for i in (range(im_array.shape[0])):\n        img1 = im_array[i]\n        if(i !=im_array.shape[0] - 1):\n            img2 = im_array[i+1]\n        else:\n            img2 = im_array[i]\n        ch1, ch2 = getFlow1(img1, img2)\n        ch3 = getFlow2(img1, img2)\n        ch4 = getCanny(img1, 50, 50)\n        ch5 = getFourier(img1)\n        ch6 = getJET(img1)\n\n        if(i == 0):\n            ch1_arr = np.expand_dims(ch1, axis = 0)\n        else:\n            ch1_arr = np.concatenate((ch1_arr, np.expand_dims(ch1, axis = 0)), axis = 0)\n\n        if(i == 0):\n            ch2_arr = np.expand_dims(ch2, axis = 0)\n        else:\n            ch2_arr = np.concatenate((ch2_arr, np.expand_dims(ch2, axis = 0)), axis = 0)\n\n        if(i == 0):\n            ch3_arr = np.expand_dims(ch3, axis = 0)\n        else:\n            ch3_arr = np.concatenate((ch3_arr, np.expand_dims(ch3, axis = 0)), axis = 0)\n\n        if(i == 0):\n            ch4_arr = np.expand_dims(ch4, axis = 0)\n        else:\n            ch4_arr = np.concatenate((ch4_arr, np.expand_dims(ch4, axis = 0)), axis = 0)\n\n        if(i == 0):\n            ch5_arr = np.expand_dims(ch5, axis = 0)\n        else:\n            ch5_arr = np.concatenate((ch5_arr, np.expand_dims(ch5, axis = 0)), axis = 0)\n\n        if(i == 0):\n            ch6_arr = np.expand_dims(ch6, axis = 0)\n        else:\n            ch6_arr = np.concatenate((ch6_arr, np.expand_dims(ch6, axis = 0)), axis = 0)\n\n    im_array = np.expand_dims(im_array, axis = 3)\n    ch1_arr = np.expand_dims(ch1_arr, axis = 3)\n    ch2_arr = np.expand_dims(ch2_arr, axis = 3)\n    ch3_arr = np.expand_dims(ch3_arr, axis = 3)\n    ch4_arr = np.expand_dims(ch4_arr, axis = 3)\n    ch5_arr = np.expand_dims(ch5_arr, axis = 3)\n    ch6_arr = np.expand_dims(ch6_arr, axis = 3)\n\n\n\n    arr = np.concatenate((im_array, ch1_arr), axis = 3)\n    arr = np.concatenate((arr, ch2_arr), axis = 3)\n    arr = np.concatenate((arr, ch3_arr), axis = 3)\n    arr = np.concatenate((arr, ch4_arr), axis = 3)\n    arr = np.concatenate((arr, ch5_arr), axis = 3)\n    arr = np.concatenate((arr, ch6_arr), axis = 3)\n\n    if(flag == False):\n        my_data = np.expand_dims(arr, axis = 0)\n        flag = True\n    else:\n        my_data = np.concatenate((my_data, np.expand_dims(arr, axis = 0)), axis = 0)\n        \n    return arr\n\n\ndef getData(root):\n    my_data = np.empty((1))\n    flag = False\n    for ix in tqdm(os.listdir(root)): \n        folder = os.path.join(root, ix)\n        print(folder)\n        read = lambda imname: np.asarray((Image.open(imname).convert(\"L\")).resize((320, 240), Image.ANTIALIAS))\n        ims = [read(os.path.join(folder, filename)) for filename in os.listdir(folder)]\n        im_array = np.array(ims, dtype='uint8')    \n\n        ch1_arr = np.empty((1))\n        ch2_arr = np.empty((1))\n        ch3_arr = np.empty((1))\n        ch4_arr = np.empty((1))\n        ch5_arr = np.empty((1))\n        ch6_arr = np.empty((1))\n\n        for i in tqdm(range(im_array.shape[0])):\n            img1 = im_array[i]\n            if(i !=im_array.shape[0] - 1):\n                img2 = im_array[i+1]\n            else:\n                img2 = im_array[i]\n            ch1, ch2 = getFlow1(img1, img2)\n            ch3 = getFlow2(img1, img2)\n            ch4 = getCanny(img1, 50, 50)\n            ch5 = getFourier(img1)\n            ch6 = getJET(img1)\n\n            if(i == 0):\n                ch1_arr = np.expand_dims(ch1, axis = 0)\n            else:\n                ch1_arr = np.concatenate((ch1_arr, np.expand_dims(ch1, axis = 0)), axis = 0)\n\n            if(i == 0):\n                ch2_arr = np.expand_dims(ch2, axis = 0)\n            else:\n                ch2_arr = np.concatenate((ch2_arr, np.expand_dims(ch2, axis = 0)), axis = 0)\n\n            if(i == 0):\n                ch3_arr = np.expand_dims(ch3, axis = 0)\n            else:\n                ch3_arr = np.concatenate((ch3_arr, np.expand_dims(ch3, axis = 0)), axis = 0)\n\n            if(i == 0):\n                ch4_arr = np.expand_dims(ch4, axis = 0)\n            else:\n                ch4_arr = np.concatenate((ch4_arr, np.expand_dims(ch4, axis = 0)), axis = 0)\n\n            if(i == 0):\n                ch5_arr = np.expand_dims(ch5, axis = 0)\n            else:\n                ch5_arr = np.concatenate((ch5_arr, np.expand_dims(ch5, axis = 0)), axis = 0)\n\n            if(i == 0):\n                ch6_arr = np.expand_dims(ch6, axis = 0)\n            else:\n                ch6_arr = np.concatenate((ch6_arr, np.expand_dims(ch6, axis = 0)), axis = 0)\n\n        im_array = np.expand_dims(im_array, axis = 3)\n        ch1_arr = np.expand_dims(ch1_arr, axis = 3)\n        ch2_arr = np.expand_dims(ch2_arr, axis = 3)\n        ch3_arr = np.expand_dims(ch3_arr, axis = 3)\n        ch4_arr = np.expand_dims(ch4_arr, axis = 3)\n        ch5_arr = np.expand_dims(ch5_arr, axis = 3)\n        ch6_arr = np.expand_dims(ch6_arr, axis = 3)\n\n\n\n        arr = np.concatenate((im_array, ch1_arr), axis = 3)\n        arr = np.concatenate((arr, ch2_arr), axis = 3)\n        arr = np.concatenate((arr, ch3_arr), axis = 3)\n        arr = np.concatenate((arr, ch4_arr), axis = 3)\n        arr = np.concatenate((arr, ch5_arr), axis = 3)\n        arr = np.concatenate((arr, ch6_arr), axis = 3)\n\n\n        if(flag == False):\n            my_data = np.expand_dims(arr, axis = 0)\n            flag = True\n        else:\n            my_data = np.concatenate((my_data, np.expand_dims(arr, axis = 0)), axis = 0)\n        \n    return arr      \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tqdm\nimport os\nfrom tqdm import tqdm_notebook as tqdm\nfrom PIL import Image\nimport cv2\n\n\ndef getFlow1(img1, img2):\n    flow = cv2.calcOpticalFlowFarneback(img2, img1, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n    ang =  0.5 * ang * 180 / np.pi\n    mag = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n    return ang, mag\n\n\ndef getFlow2(img1, img2):\n    feature_params = dict( maxCorners = 100,\n                           qualityLevel = 0.3,\n                           minDistance = 7,\n                           blockSize = 7 )\n\n    lk_params = dict( winSize  = (15,15),\n                      maxLevel = 2,\n                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n    p0 = cv2.goodFeaturesToTrack(img1, mask = None, **feature_params)\n    p1, st, err = cv2.calcOpticalFlowPyrLK(img1, img2, p0, None, **lk_params)\n    color = np.random.randint(0,255,(100,3))\n    mask = np.zeros_like(img1)\n\n    # Select good points\n    good_new = p1[st==1]\n    good_old = p0[st==1]\n    # draw the tracks\n    for i,(new,old) in enumerate(zip(good_new,good_old)):\n        a,b = new.ravel()\n        c,d = old.ravel()\n        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n\n    return mask\n\ndef getCanny(img, t1, t2):\n    return cv2.Canny(img, t1, t2)\n\n\n\ndef getFourier(img):\n    f = np.fft.fft2(img)\n    fshift = np.fft.fftshift(f)\n    magnitude_spectrum = 20*np.log(np.abs(fshift))\n    return magnitude_spectrum\n\n\ndef getJET(img):\n    f = np.fft.fft2(img)\n    fshift = np.fft.fftshift(f)\n    rows, cols = img.shape\n    crow,ccol = rows/2 , cols/2\n    crow = int(crow)\n    ccol = int(ccol)\n    fshift[crow-30:crow+30, ccol-30:ccol+30] = 0\n    f_ishift = np.fft.ifftshift(fshift)\n    img_back = np.fft.ifft2(f_ishift)\n    img_back = np.abs(img_back)\n    return img_back","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nM = 1000\nTx = 50\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n\nclass ConvModel(nn.Module):\n    def __init__(self):\n        super(ConvModel, self).__init__()\n\n        self.layer1 = nn.Sequential(\n\t        nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(7, 11), stride=(2, 2)),\n\t        nn.ReLU(),\n\t        nn.MaxPool2d(kernel_size=(2, 2), stride=(1,1)))\n        self.layer2 = nn.Sequential(\n\t        nn.Conv2d(in_channels=2, out_channels=4, kernel_size=(7, 9), stride=(2, 2)),\n\t        nn.ReLU(), \n\t        nn.MaxPool2d(kernel_size=(2, 2), stride=(1,1)))  \t\n        self.layer3 = nn.Sequential(\n\t     \tnn.Conv2d(in_channels = 4, out_channels=8, kernel_size = (5, 7), stride=(2,2)), \n\t     \tnn.ReLU())  \t\n        self.layer4 = nn.Sequential(\n\t\t\tnn.Conv2d(in_channels = 8, out_channels=16, kernel_size = (3, 5), stride=(2,2)), \n\t     \tnn.ReLU(),\n\t     \tnn.MaxPool2d(kernel_size=(2, 2), stride=(1,1)))  \n        self.fc1 = nn.Sequential(\n\t        nn.Linear(11*14*16, out_features=1400),\n\t        nn.ReLU()\n        )\n        self.fc2 = nn.Sequential(\n\t        nn.Linear(1400, out_features=600),\n\t        nn.ReLU()\n        )\n        self.LSTM1 =  nn.LSTM(input_size=600, hidden_size=150, num_layers=1, bidirectional= True)\n        self.LSTM2 =  nn.LSTM(input_size=300, hidden_size=75, num_layers=2, bidirectional=True)\n        self.LSTM3 =  nn.LSTM(input_size=150, hidden_size=25, num_layers=2, bidirectional=True)\n        self.LSTM4 =  nn.LSTM(input_size=50, hidden_size=8, num_layers=3, bidirectional=True)\n        self.LSTM5 =  nn.LSTM(input_size=16, hidden_size=2, num_layers=3, bidirectional=True)\n        self.LSTM6 =  nn.LSTM(input_size=4, hidden_size=1, num_layers=1)\n        for name, param in self.LSTM1.named_parameters():\n            if 'bias' in name:\n                nn.init.constant(param, 0.0)\n            elif 'weight' in name:\n                nn.init.xavier_normal(param)\n        for name, param in self.LSTM2.named_parameters():\n            if 'bias' in name:\n                nn.init.constant(param, 0.0)\n            elif 'weight' in name:\n                nn.init.xavier_normal(param)\n        for name, param in self.LSTM3.named_parameters():\n            if 'bias' in name:\n                nn.init.constant(param, 0.0)\n            elif 'weight' in name:\n                nn.init.xavier_normal(param)\n        for name, param in self.LSTM4.named_parameters():\n            if 'bias' in name:\n                nn.init.constant(param, 0.0)\n            elif 'weight' in name:\n                nn.init.xavier_normal(param)\n        for name, param in self.LSTM5.named_parameters():\n            if 'bias' in name:\n                nn.init.constant(param, 0.0)\n            elif 'weight' in name:\n                nn.init.xavier_normal(param)\n        for name, param in self.LSTM6.named_parameters():\n            if 'bias' in name:\n                nn.init.constant(param, 0.0)\n            elif 'weight' in name:\n                nn.init.xavier_normal(param)\n    def forward(self, x, Tx, M):\n        out=self.layer1(x)\n#        print(out.shape)\n        out=self.layer2(out)\n#        print(out.shape)\n        out=self.layer3(out)\n#        print(out.shape)\n        out=self.layer4(out)\n        out = out.reshape(out.size(0), -1)\n#        print(out.shape)\n        out = self.fc1(out)\n#        print(out.shape)\n        out = self.fc2(out)\n#        print(out.shape)\n        input = out.reshape(Tx,M,-1)\n        input, _=self.LSTM1(input)\n        input, _=self.LSTM2(input)\n        input, _=self.LSTM3(input)\n        input, _=self.LSTM4(input)\n        input, _=self.LSTM5(input)\n        input, _=self.LSTM6(input)\n #       print(input.shape)\n        y_out   =nn.Sigmoid()(input)\n        return y_out    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr = arr[:, :, :, 0]\narr= torch.from_numpy(arr).to(device)\narr = arr.reshape((-1, 1, 240, 320)).float()\nprint(arr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nout= model.forward(arr.float(), Tx, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = np.load('../input/true-labels/copied_labels/copied_labels/1.npy')\nlabels =  np.reshape(labels, (Tx,1))\nlabels = torch.from_numpy(labels).float().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss=torch.nn.functional.binary_cross_entropy(out, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Tx=50\nmodel = ConvModel().to(device)\nnum_epochs = 20\nlearning_rate = 0.08\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\ndatalist= os.listdir('../input/dataset-a2/copied/copied/')\ndatalist.sort()\npath1 = '../input/dataset-a2/copied/copied/'\npath2 = '../input/true-labels/copied_labels/copied_labels/'\nlabelist = os.listdir('../input/true-labels/copied_labels/copied_labels/')\nlabelist.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_list = []\nfor epochs in (range(num_epochs)):\n    for i in tqdm(range(1, 12)):\n        pathFile = path1+datalist[i]+'/'\n        labelFile= path2+datalist[i]+'.npy'\n        labels = np.load(labelFile)\n        arr = fetch(pathFile)\n        arr = arr[:, :, :, 0]\n        arr= torch.from_numpy(arr).to(device)\n        arr = arr.reshape((-1, 1, 240, 320))\n        arr = arr.float()\n        labels =  np.reshape(labels, (Tx,1))\n        labels = torch.from_numpy(labels).float()\n        labels = labels.to(device)\n        output = model.forward(arr, Tx, 1)\n        output = output.reshape(-1, 1)\n        loss = torch.nn.functional.binary_cross_entropy(output, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        loss_list.append(loss)\n        \n        if (i+1) % 3 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epochs+1, num_epochs, i+1, 11,  loss.item()))\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    correct = 0\n    it = 0\n    for i in tqdm(range(220, 230)):\n        it=it+1\n        pathFile = path1+datalist[i]+'/'\n        labelFile= path2+labelist[i]\n        labels = np.load(labelFile)\n        arr = fetch(pathFile)\n        arr = arr[:, :, :, 0]\n        arr= torch.from_numpy(arr).to(device)\n        arr = arr.reshape((-1, 1, 240, 320))\n        arr = arr.float()\n        labels =  np.reshape(labels, (Tx,1))\n#         labels = torch.from_numpy(labels).float()\n#         labels = labels.to(device)\n\n        output = model.forward(arr, Tx, 1)\n        output = output.reshape(-1, 1)\n        output = output > 0.5\n        output =  output.cpu().numpy()\n        if np.amax(output) ==1:\n            print('yahhhheehhea')\n        results = labels == output\n        correct=correct+np.sum(results)\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct/(it*50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"llist= np.asarray(loss_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(llist[0:25])","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}